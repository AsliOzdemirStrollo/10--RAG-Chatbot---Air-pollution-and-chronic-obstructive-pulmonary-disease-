## ğŸ« Air Pollution & COPD â€“ RAG Chatbot

A question-answering chatbot built using Retrieval-Augmented Generation (RAG), designed to explain scientific findings from the research article:

**â€œAir pollution and chronic obstructive pulmonary disease (COPD)â€**

ğŸ‘‰ **Live App:** https://rag-chatbot-airpollution.streamlit.app/  
ğŸ‘‰ The PDF can also be downloaded inside the app.

The chatbot reads the paper, retrieves the most relevant parts, and answers questions using only verified information from the article.

---

## ğŸ¯ What This Project Does

This project builds an intelligent assistant that can:

- Answer medical and scientific questions about COPD and air pollution  
- Retrieve and reference correct sections of the research paper  
- Avoid hallucinations and stay fully grounded in the PDF  
- Provide clear explanations for complex biological mechanisms  
- Combine information across multiple sections  

---

## ğŸ§  Development Process

The system was built through several improvement stages:

### 1. Baseline RAG  
Initial retrieval + generation pipeline to observe weaknesses.

### 2. Chunking Optimization  
Experimented with multiple configurations.  
**Best performing:**  
- `chunk_size = 512`  
- `chunk_overlap = 80`

### 3. Reranking  
Added a reranker (`reranker_n = 2`) to improve retrieval precision.

### 4. Query Rewriting + HyDE  
Two major upgrades:
- **Condense+Context rewriting** clarifies user questions  
- **HyDE** generates a hypothetical answer to improve retrieval quality  

This dramatically improves performance on complex, multi-part questions.

### 5. Final Tuning  
Adjusted parameters to maximize grounding and recall.

---

## ğŸ“Š Evaluation Results (6 Questions)

This evaluation used **six challenging scientific questions**, each requiring:

- Mechanistic biological explanation  
- Pollutant-specific comparisons (PM2.5, PM10, NOâ‚‚, Oâ‚ƒ, SOâ‚‚)  
- Mortality + prevalence interpretation  
- Regional differences (UK, China, Europe)  
- Reading epidemiological tables  
- Synthesizing information across multiple PDF sections  

### **Final Scores (6-Question Evaluation)**  
- ğŸŸ¢ **Faithfulness = 1.0 â†’ zero hallucinations**  
- ğŸ”µ Strong context recall  
- ğŸŸ¡ Lower precision â€” expected because the questions became much harder  

---

## ğŸ“ Interpretation of the Evaluation Summary

These six questions were **intentionally much harder** than standard RAG benchmarks.  
They require deep reasoning rather than simply retrieving one paragraph.

**Why precision drops on hard questions:**

- Hard questions require *multiple* correct contexts  
- The retriever brings in several related chunks  
- Some chunks contain only partial relevance  
- Ragas counts those as â€œlower precision,â€ even if the answer is excellent  

This is **normal** and expected for multi-topic scientific reasoning tasks.

### â­ What matters most: **Faithfulness = 1.0**  
The chatbot **never hallucinated** and **every answer was grounded** in the PDF.

### â­ Recall stays strong  
It consistently retrieves relevant scientific sections.

### â­ Final verdict  
The system remains:

- **Scientifically reliable**  
- **Highly accurate**  
- **Ideal for biomedical question answering**  
- **Robust for multi-step reasoning**  

---

## âœ¨ Understanding Misspellings & Short Queries

The chatbot understands questions even when they contain:

- Typos  
- Short phrases  
- Shorthand  
- Country-only queries  
- Incomplete scientific terms  

Examples it handles correctly:

- â€œwhat about the UK?â€  
- â€œmortality?â€  
- â€œcopd mechansims?â€  
- â€œpollution effects china?â€  

Thanks to:

### ğŸ§© **Condense+Context Query Rewriting**  
It rewrites unclear inputs into full, structured scientific questions.

### ğŸ§© **HyDE (Hypothetical Document Embeddings)**  
Creates a synthetic answer to improve retrieval precision.

ğŸ”¥ This allows the chatbot to understand what the user *meant*,  
while still staying **100% grounded in the PDF**.

---

## ğŸ–¼ï¸ Evaluation Summary Images

![Evaluation Results](images/summary_.png)

---

## ğŸ“¦ Project Structure

```text
RAG-Project/
â”‚
â”œâ”€â”€ data/                      # Text file used for RAG indexing
â”‚   â””â”€â”€ air_pollution.txt
â”‚
â”œâ”€â”€ data_pdf/                  # PDF only for user download (NOT used for RAG)
â”‚   â””â”€â”€ air_pollution.pdf
â”‚
â”œâ”€â”€ evaluation/                # Evaluation pipeline using Ragas
â”‚   â”œâ”€â”€ evaluation_config.py
â”‚   â”œâ”€â”€ evaluation_engine.py
â”‚   â”œâ”€â”€ evaluation_model_loader.py
â”‚   â”œâ”€â”€ evaluation_questions.py
â”‚   â”œâ”€â”€ evaluation_helper_functions.py
â”‚   â””â”€â”€ evaluation_results/
â”‚
â”œâ”€â”€ images/                    # Evaluation summary visuals
â”‚   â””â”€â”€ summary_.png
â”‚
â”œâ”€â”€ src/                       # Core RAG implementation
â”‚   â”œâ”€â”€ config.py              # Global configuration (incl. vector_store_v4 path)
â”‚   â”œâ”€â”€ engine.py              # Chat engine with HyDE, reranking, query rewriting
â”‚   â””â”€â”€ model_loader.py        # LLM + embedding initializers
â”‚
â”œâ”€â”€ local_storage/             # Auto-generated index & embeddings (git-ignored)
â”‚   â”œâ”€â”€ embedding_model/
â”‚   â”œâ”€â”€ vector_store/          # Old versions (ignored)
â”‚   â””â”€â”€ vector_store_v4/       # Current production index
â”‚
â”œâ”€â”€ .gitignore                 # Ensures vector stores & caches are NOT committed
â”œâ”€â”€ app.py                     # Streamlit UI for the chatbot
â”œâ”€â”€ evaluate.py                # Script to run full evaluation
â”œâ”€â”€ main.py                    # Optional local CLI chatbot
â”œâ”€â”€ requirements.txt           # Project dependencies
â””â”€â”€ README.md                  # Documentation

---
## ğŸš€ Try the App

ğŸ‘‰ **https://rag-chatbot-airpollution.streamlit.app/**

Ask scientific questions, explore the PDF, and test the retrieval accuracy in real time.
